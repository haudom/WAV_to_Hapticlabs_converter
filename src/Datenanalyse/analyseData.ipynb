{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenschaften der Signale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import openFile\n",
    "from main import getAmplitudes\n",
    "from main import findBreaks\n",
    "from main import PlotInterminResults\n",
    "from main import interpolate\n",
    "from main import splitAudioArrAtBreaks\n",
    "from main import rms\n",
    "import aiBasefrequency\n",
    "import numpy\n",
    "from itables import init_notebook_mode\n",
    "from itables import show\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "#Module settings\n",
    "init_notebook_mode(all_interactive=True)\n",
    "PlotInterminResults(False)\n",
    "\n",
    "\n",
    "folder = r\"../viblib\" #Ordner mit .wav Dateien\n",
    "\n",
    "#############################################################################\n",
    "# Sucht alle Wav-Dateien im Ordner und gibt deren Namen als Liste zurück\n",
    "#############################################################################\n",
    "def loadFileList():\n",
    "#Lädt json Datei und gibt Inhalt als string zurück\n",
    "  return {f for f in os.listdir(folder) if f.endswith('.wav')}\n",
    "\n",
    "#############################################################################\n",
    "# Sucht alle Stellen an denen das Signal steigt und gibt die gesammtsteigung und die Gesamtdauer der Steigungen zurück\n",
    "#############################################################################\n",
    "def increase(arr,tolerance,sr=16000):\n",
    "   increases =  []\n",
    "   increases.append([])\n",
    "   for i, sample in enumerate(arr):\n",
    "      if i == len(arr)-1:\n",
    "         break\n",
    "      if arr[i] < arr[i+1]:\n",
    "         increases[-1].append(arr[i+1])\n",
    "      else:\n",
    "         if len(increases[-1]) > 0:\n",
    "            increases.append([])\n",
    "   mList = []\n",
    "   durations = []\n",
    "   for increase in increases:\n",
    "     if len(increase) > 0:\n",
    "      duration = len(increase)/sr\n",
    "      amplitudeDiff = increase[-1] - increase[0]\n",
    "      if amplitudeDiff/duration > tolerance:\n",
    "        mList.append(amplitudeDiff / duration)\n",
    "        durations.append(duration)\n",
    "   \n",
    "   if len(mList) > 0:\n",
    "    return numpy.average(mList,weights=durations), sum(durations)\n",
    "   else: return 0, 0\n",
    "\n",
    "#############################################################################\n",
    "# Sucht alle Stellen an denen das Signal sinkt und gibt die gesammtsteigung und die Gesamtdauer der Steigungen zurück\n",
    "#############################################################################\n",
    "def decrease(arr,tolerance,sr=16000):\n",
    "   decreasees =  []\n",
    "   decreasees.append([])\n",
    "   for i, sample in enumerate(arr):\n",
    "      if i == len(arr)-1:\n",
    "        break\n",
    "      if arr[i] > arr[i+1]:\n",
    "         decreasees[-1].append(arr[i+1])\n",
    "      else:\n",
    "         if len(decreasees[-1]) > 0:\n",
    "            decreasees.append([])\n",
    "   mList = []\n",
    "   durations = []\n",
    "   for decrease in decreasees:\n",
    "     if len(decrease) > 0:\n",
    "      duration = len(decrease)/sr\n",
    "      amplitudeDiff = decrease[-1] - decrease[0]\n",
    "      if amplitudeDiff < -tolerance*duration:\n",
    "        mList.append(amplitudeDiff / duration)\n",
    "        durations.append(duration)\n",
    "   if len(mList) > 0:\n",
    "    return numpy.average(mList,weights=durations), sum(durations)\n",
    "   else: return 0, 0\n",
    "\n",
    "#############################################################################\n",
    "# Pausen aus Amplituden filtern (Da Amplituden Algorithmus dort nicht funktioniert)\n",
    "#############################################################################\n",
    "def filterPause(arr,breaks):\n",
    "  for b in breaks:\n",
    "    for i in range(b[0],b[1]):\n",
    "      arr[i] = 0\n",
    "  return arr\n",
    "\n",
    "#############################################################################\n",
    "# Plot der Signale\n",
    "#############################################################################\n",
    "def plot_to_base64(data,y_scale):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(2,1)\n",
    "    ax.plot(data)\n",
    "    ax.set_ylim(y_scale[0],y_scale[1])\n",
    "    \n",
    "    # Plot in einen Bytes-Buffer speichern\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Bild zu base64 kodieren\n",
    "    buf.seek(0)\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    return f'<img src=\"data:image/png;base64,{img_base64}\" height=\"50\"/>'\n",
    "\n",
    "#############################################################################\n",
    "# Durchschschnittliche Zeit zwischen zwei Pausen\n",
    "#############################################################################\n",
    "def meanSinDuration(breaks,signal_arr,sr):\n",
    "  if len(breaks) == 0: return len(signal_arr)/sr\n",
    "  splits = splitAudioArrAtBreaks(signal_arr,breaks)\n",
    "  return numpy.average([len(split) for split in splits])/sr\n",
    "\n",
    "#############################################################################\n",
    "# Signalenergie ohne Pausen\n",
    "#############################################################################\n",
    "def signalEnergyWithoutBreaks(breaks,signal_arr):\n",
    "  if len(breaks) == 0: return rms(signal_arr)\n",
    "  splits = splitAudioArrAtBreaks(signal_arr,breaks)\n",
    "  return numpy.average([rms(split) for split in splits])\n",
    "\n",
    "# Plot der Signale\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "signalAnalyses = {}\n",
    "\n",
    "for name in loadFileList():\n",
    "    filePath = os.path.join(folder, name)\n",
    "    signal_arr, sr = openFile(filePath)\n",
    "    name = os.path.splitext(name)[0]\n",
    "    signalAnalyses[name] = {}\n",
    "    \n",
    "    breaks = findBreaks(signal_arr, sr)\n",
    "    frequencies, _ = aiBasefrequency.getFrequencies(signal_arr)\n",
    "    frequencies = aiBasefrequency.outputTooHz(frequencies)\n",
    "    frequencies = numpy.interp(range(0,len(signal_arr)), numpy.arange(0,len(frequencies)*512,512),frequencies,right=frequencies[-1])\n",
    "    signalAnalyses[name][\"signal\"] = plot_to_base64(signal_arr,[-1,1])\n",
    "    signalAnalyses[name][\"frequency\"] = plot_to_base64(frequencies,[0,1000])\n",
    "\n",
    "    rawAmplitudes = getAmplitudes(signal_arr, sr)\n",
    "    amplitudes = interpolate(rawAmplitudes, len(signal_arr))\n",
    "    amplitudes = filterPause(amplitudes,breaks)\n",
    "    signalAnalyses[name][\"amplitude\"] = plot_to_base64(amplitudes,[0,1])\n",
    "\n",
    "    signalAnalyses[name][\"duration\"] = len(signal_arr)/sr\n",
    "\n",
    "    \n",
    "    signalAnalyses[name][\"breakTotalDuration\"] = (numpy.sum([b[1] - b[0] for b in breaks]))/sr\n",
    "    signalAnalyses[name][\"meanBreakDuration\"] = signalAnalyses[name][\"breakTotalDuration\"] / len(breaks)\n",
    "    signalAnalyses[name][\"breaksCount\"] = len(breaks)\n",
    "\n",
    "\n",
    "    incAmplitudes, durationIncAmp = increase(amplitudes,0.02,sr)\n",
    "    decAmplitudes, durationDecAmp = decrease(amplitudes,0.02,sr)\n",
    "    incFrequency, durationIncFreq = increase(frequencies,1,sr)\n",
    "    decFrequency, durationDecFreq = decrease(frequencies,1,sr)\n",
    "    signalAnalyses[name][\"NoFrequencyChangeDuration\"] = signalAnalyses[name][\"duration\"] - (durationIncFreq + durationDecFreq)\n",
    "    signalAnalyses[name][\"NoAmplitudeChangeDuration\"] = signalAnalyses[name][\"duration\"] - (durationIncAmp + durationDecAmp)\n",
    "    signalAnalyses[name][\"NoFrequencyChangeDurationRelative\"] = signalAnalyses[name][\"NoFrequencyChangeDuration\"] / signalAnalyses[name][\"duration\"] * 100\n",
    "    signalAnalyses[name][\"NoAmplitudeChangeDurationRelative\"] = signalAnalyses[name][\"NoAmplitudeChangeDuration\"] / signalAnalyses[name][\"duration\"] * 100\n",
    "    signalAnalyses[name][\"meanFrequency\"] = numpy.mean(frequencies)\n",
    "\n",
    "    signalAnalyses[name][\"increaseRateFrequency\"] = durationIncFreq\n",
    "    signalAnalyses[name][\"decreaseRateFrequency\"] = durationDecFreq\n",
    "    signalAnalyses[name][\"increaseRateAmplitude\"] = incAmplitudes\n",
    "    signalAnalyses[name][\"decreaseRateAmplitude\"] = decAmplitudes\n",
    "    signalAnalyses[name][\"meanTimeBetweenBreaks\"] = meanSinDuration(breaks,signal_arr,sr)\n",
    "    signalAnalyses[name][\"meanSignalEnergyWithoutBreaks\"] = signalEnergyWithoutBreaks(breaks,signal_arr)\n",
    "    \n",
    "\n",
    "## Entfernen dre signal und frequenzspalte\n",
    "# Spalten, die ausgeschlossen werden sollen:\n",
    "\"\"\" spalten_ausschliessen = ['signal', 'frequency']\n",
    "# Kopie des Dictionaries erstellen, ohne die unerwünschten Spalten:\n",
    "signalAnalyses_filtered = {\n",
    "    key: {k: v for k, v in value.items() if k not in spalten_ausschliessen}\n",
    "    for key, value in signalAnalyses.items()\n",
    "} \"\"\"\n",
    "\n",
    "signalAnalysesDF = pd.DataFrame.from_dict(signalAnalyses, orient='index')\n",
    "\n",
    "\n",
    "signalAnalysesDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Laden und Daten aufbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "words = {\"sensationTags\":[],\n",
    "         \"emotionTags\":[],\n",
    "         \"metaphors\":[],\n",
    "         \"usageExamples\":[]}\n",
    "#Datei öffnen\n",
    "csv_path = r\"C:\\Users\\Domin\\OneDrive\\HTW\\Bachelorarbeit\\WAVTactilTransformer\\viblib\\vibrationAnnotations-July24th2016.csv\"\n",
    "df = pd.read_csv(csv_path, sep=',', header=0, index_col=0, decimal='.', usecols=[\"id\",\"sensationTags\",\"emotionTags\",\"metaphors\",\"usageExamples\"], dtype={\"id\":str,\"sensationTags\":str,\"emotionTags\":str,\"metaphors\":str,\"usageExamples\":str},na_filter=False)\n",
    "\n",
    "#finde Alarm tags und benenne sie um, da sie in mataphors und usageExamples vorkommen\n",
    "for index, row in df.iterrows():\n",
    "    tags = row[\"usageExamples\"].split(\",\")\n",
    "    if \"alarm\" in tags:\n",
    "        alarmIndex = tags.index(\"alarm\")\n",
    "        tags[alarmIndex] = \"alarm-usageExamples\"\n",
    "        df[\"usageExamples\"][index] = \",\".join(tags)\n",
    "    tags = row[\"metaphors\"].split(\",\")\n",
    "    if \"alarm\" in tags:\n",
    "        alarmIndex = tags.index(\"alarm\")\n",
    "        tags[alarmIndex] = \"alarm-metaphors\"\n",
    "        df[\"metaphors\"][index] = \",\".join(tags)\n",
    "\n",
    "#alle vorkommenden Tags nach Fasetten aufteilen\n",
    "heads = [\"sensationTags\",\"emotionTags\",\"metaphors\",\"usageExamples\"]\n",
    "for index, row in df.iterrows():\n",
    "    for head in heads:\n",
    "        tags=row[head].split(\",\")\n",
    "        for tag in tags:\n",
    "            if tag not in words[head]:\n",
    "                words[head].append(tag)\n",
    "\n",
    "\n",
    "#liste mit allen vorkommenden Tags\n",
    "allTags = words[\"sensationTags\"]+words[\"emotionTags\"]+words[\"metaphors\"]+words[\"usageExamples\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenschaften der Signale pro Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysePerTag = {}\n",
    "for category in words:\n",
    "    for tag in words[category]:\n",
    "        analysePerTag[tag] = {\"category\":category \n",
    "                              , \"IDs\" : []}\n",
    "        \n",
    "for index, row in df.iterrows():\n",
    "    tags = (row[\"sensationTags\"]+\",\"+row[\"emotionTags\"]+\",\"+row[\"metaphors\"]+\",\"+row[\"usageExamples\"]).split(\",\")\n",
    "    for tag in tags:\n",
    "        try:\n",
    "            signalAnalyses[index]\n",
    "            analysePerTag[tag][\"IDs\"].append(index)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "import numpy as np       \n",
    "\n",
    "for tag in analysePerTag:\n",
    "\n",
    "    analysePerTag[tag][\"meanDuration\"] = np.mean([signalAnalyses[ID][\"duration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdDuration\"] = np.std([signalAnalyses[ID][\"duration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"minDuration\"] = np.min([signalAnalyses[ID][\"duration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"maxDuration\"] = np.max([signalAnalyses[ID][\"duration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanTotalBreakDuration\"] = np.mean([signalAnalyses[ID][\"breakTotalDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdTotalBreakDuration\"] = np.std([signalAnalyses[ID][\"breakTotalDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanBreakCount\"] = np.mean([signalAnalyses[ID][\"breaksCount\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdBreakCount\"] = np.std([signalAnalyses[ID][\"breaksCount\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanBreakDuration\"] = np.nanmean([signalAnalyses[ID][\"meanBreakDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdBreakDuration\"] = np.nanstd([signalAnalyses[ID][\"meanBreakDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanNoFrequencyChangeDuration\"] = np.mean([signalAnalyses[ID][\"NoFrequencyChangeDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdNoFrequencyChangeDuration\"] = np.std([signalAnalyses[ID][\"NoFrequencyChangeDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanNoAmplitudeChangeDuration\"] = np.mean([signalAnalyses[ID][\"NoAmplitudeChangeDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdNoAmplitudeChangeDuration\"] = np.std([signalAnalyses[ID][\"NoAmplitudeChangeDuration\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"MeanNoFrequencyChangeDurationRelative\"] = np.mean([signalAnalyses[ID][\"NoFrequencyChangeDurationRelative\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdNoFrequencyChangeDurationRelative\"] = np.std([signalAnalyses[ID][\"NoFrequencyChangeDurationRelative\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"MeanNoAmplitudeChangeDurationRelative\"] = np.mean([signalAnalyses[ID][\"NoAmplitudeChangeDurationRelative\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdNoAmplitudeChangeDurationRelative\"] = np.std([signalAnalyses[ID][\"NoAmplitudeChangeDurationRelative\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanIncreaseRateFrequency\"] = np.mean([signalAnalyses[ID][\"increaseRateFrequency\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdIncreaseRateFrequency\"] = np.std([signalAnalyses[ID][\"increaseRateFrequency\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanFrequency\"] = np.mean([signalAnalyses[ID][\"meanFrequency\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdMeanFrequency\"] = np.std([signalAnalyses[ID][\"meanFrequency\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "\n",
    "    analysePerTag[tag][\"meanIncreaseRateAmplitude\"] = np.mean([signalAnalyses[ID][\"increaseRateAmplitude\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdIncreaseRateAmplitude\"] = np.std([signalAnalyses[ID][\"increaseRateAmplitude\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanDecreaseRateFrequency\"] = np.mean([signalAnalyses[ID][\"decreaseRateFrequency\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdDecreaseRateFrequency\"] = np.std([signalAnalyses[ID][\"decreaseRateFrequency\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanDecreaseRateAmplitude\"] = np.mean([signalAnalyses[ID][\"decreaseRateAmplitude\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdDecreaseRateAmplitude\"] = np.std([signalAnalyses[ID][\"decreaseRateAmplitude\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanTimeBetweenBreaks\"] = np.mean([signalAnalyses[ID][\"meanTimeBetweenBreaks\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdTimeBetweenBreaks\"] = np.std([signalAnalyses[ID][\"meanTimeBetweenBreaks\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "    analysePerTag[tag][\"meanSignalEnergyWithoutBreaks\"] = np.mean([signalAnalyses[ID][\"meanSignalEnergyWithoutBreaks\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "    analysePerTag[tag][\"stdSignalEnergyWithoutBreaks\"] = np.std([signalAnalyses[ID][\"meanSignalEnergyWithoutBreaks\"] for ID in analysePerTag[tag][\"IDs\"]])\n",
    "\n",
    "\n",
    "analysePerTagDf=pd.DataFrame.from_dict(analysePerTag,orient=\"index\")\n",
    "analysePerTagDf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot long short\n",
    "\n",
    "dataLong = [signalAnalyses[ID][\"duration\"] for ID in analysePerTag[\"long\"][\"IDs\"]]\n",
    "dataShort = [signalAnalyses[ID][\"duration\"] for ID in analysePerTag[\"short\"][\"IDs\"]]\n",
    "plt.title(\"boxplot der Dauer von \\\"long\\\"\")\n",
    "plt.boxplot([signalAnalyses[ID][\"duration\"] for ID in analysePerTag[\"long\"][\"IDs\"]])\n",
    "plt.figure()\n",
    "plt.title(\"Box-Plot der Dauer von \\\"short\\\"\")\n",
    "plt.boxplot([signalAnalyses[ID][\"duration\"] for ID in analysePerTag[\"short\"][\"IDs\"]])\n",
    "plt.figure()\n",
    "plt.title(\"Box-Plot der Signaldauer von vibrotatkilen Mustern mit den Tags \\\"long\\\" und \\\"short\\\"\")\n",
    "plt.ylabel(\"Dauer in Sekunden\")\n",
    "plt.boxplot([dataLong, dataShort], labels=[\"long\", \"short\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemeinsames Aufteten von Tags (Absolut)\n",
    "Je näher die Punkte desto öfter werden die Tags zusammen verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from IPython.core.display import display \n",
    "\n",
    "#Erstelleng des Netzwerkdiagramms\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(words[\"sensationTags\"], type=\"sensationTags\")\n",
    "G.add_nodes_from(words[\"emotionTags\"], type=\"emotionTags\")\n",
    "G.add_nodes_from(words[\"metaphors\"], type=\"metaphors\")\n",
    "G.add_nodes_from(words[\"usageExamples\"], type=\"usageExamples\")\n",
    "\n",
    "#############################################################\n",
    "#Berechnung der Kantengewichte bzw anzahl des gemeinsamen Auftretens der Tags (Absolut)\n",
    "#############################################################\n",
    "\n",
    "\n",
    "#Dictionary mit Kantengewichten\n",
    "edges = {}\n",
    "\n",
    "#Dictionary mit allen Kanten initialisieren\n",
    "for i in range(len(allTags)):\n",
    "    edges[allTags[i]] = {}\n",
    "    for j in range(i+1,len(allTags)):\n",
    "        edges[allTags[i]][allTags[j]] = 0\n",
    "\n",
    "#Hilfsfunktion zum Zählen des gemeinsamen Auftretens der Tags\n",
    "def countEdges(tag1, tag2):\n",
    "    if tag1 == tag2:\n",
    "        print(f\"Warning: {tag1} and {tag2} are the same\")\n",
    "        return\n",
    "    try:\n",
    "        edges[tag1][tag2] += 1\n",
    "    except:\n",
    "        edges[tag2][tag1] += 1\n",
    "\n",
    "#Kanten berechnen\n",
    "for index, row in df.iterrows():\n",
    "    line = (row[\"sensationTags\"]+\",\"+row[\"emotionTags\"]+\",\"+row[\"metaphors\"]+\",\"+row[\"usageExamples\"]).split(\",\")\n",
    "    for i in range(len(line)):\n",
    "        for j in range(i+1,len(line)):\n",
    "            countEdges(line[i], line[j])\n",
    "#############################################################\n",
    "\n",
    "#Graph auffüllen mit allen Infromationen\n",
    "for key in edges:\n",
    "    for key2 in edges[key]:\n",
    "        if edges[key][key2] > 0:\n",
    "            G.add_edge(key, key2, weight=edges[key][key2])\n",
    "\n",
    "#Ausgabe des Netzwerkdiagramms\n",
    "color_map = []\n",
    "for node in G:\n",
    "    if G.nodes[node]['type'] == \"sensationTags\":\n",
    "        color_map.append('red')\n",
    "    elif G.nodes[node]['type'] == \"emotionTags\":\n",
    "        color_map.append('blue')\n",
    "    elif G.nodes[node]['type'] == \"metaphors\":\n",
    "        color_map.append('green')\n",
    "    elif G.nodes[node]['type'] == \"usageExamples\":\n",
    "        color_map.append('purple')\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"Kookkurrenz Absolut\")\n",
    "\n",
    "# Legende #\n",
    "legend_labels = {\n",
    "    'red': 'sensation tags',\n",
    "    'blue': 'emotion tags',\n",
    "    'green': 'metaphors',\n",
    "    'purple': 'usage examples',\n",
    "}\n",
    "legend_handles = [mlines.Line2D([], [], color=color, linewidth=2, label=label) \n",
    "                  for color, label in legend_labels.items()]\n",
    "plt.legend(handles=legend_handles)\n",
    "##\n",
    "\n",
    "pos = nx.spring_layout(G, weight='weight',k=1.5,iterations=1000,scale=1) \n",
    "edge_weights = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw(G, pos, with_labels=True, node_color=color_map, edge_color='gray', node_size=300, font_size=4,width = 00.1)\n",
    "\n",
    "#nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_weights)\n",
    "\n",
    "nx.write_gexf(G, \"graphTotal.gexf\")\n",
    "plt.savefig(\"graphTotal.svg\")\n",
    "plt.savefig(\"graphTotal.png\")\n",
    "\n",
    "#Adjazenzmatrix\n",
    "adjTotal =nx.to_pandas_adjacency(G)\n",
    "adjTotal.to_csv(\"adj.csv\", sep=';', decimal=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anzahl der Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie oft kommt welches Tag vor?\n",
    "totalPerTagCount ={}\n",
    "for tag in allTags:\n",
    "    totalPerTagCount[tag] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tags = (row[\"sensationTags\"]+\",\"+row[\"emotionTags\"]+\",\"+row[\"metaphors\"]+\",\"+row[\"usageExamples\"]).split(\",\")\n",
    "    for tag in tags:\n",
    "        totalPerTagCount[tag] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "totalPerTagCountCategories = {\n",
    "        \"sensationTags\":{},\n",
    "        \"emotionTags\":{},\n",
    "        \"metaphors\":{},\n",
    "        \"usageExamples\":{}}\n",
    "for category in words:\n",
    "    for word in words[category]:\n",
    "        totalPerTagCountCategories[category][word] = 0\n",
    "for index, row in df.iterrows():\n",
    "    for tag in row[\"emotionTags\"].split(\",\"):\n",
    "        totalPerTagCountCategories[\"emotionTags\"][tag] +=1\n",
    "    for tag in row[\"metaphors\"].split(\",\"):\n",
    "        totalPerTagCountCategories[\"metaphors\"][tag] +=1\n",
    "    for tag in row[\"sensationTags\"].split(\",\"):\n",
    "        totalPerTagCountCategories[\"sensationTags\"][tag] +=1\n",
    "    for tag in row[\"usageExamples\"].split(\",\"):\n",
    "        totalPerTagCountCategories[\"usageExamples\"][tag] +=1\n",
    "    \n",
    "from IPython.display import HTML\n",
    "for category in totalPerTagCountCategories:\n",
    "    display(HTML(\"<h3>\"+category+\"</h3>\"))\n",
    "    dfCounts=pd.DataFrame.from_dict(data=totalPerTagCountCategories[category],orient='index',columns=[\"Anzahl des Tags\"])\n",
    "    dfCounts=dfCounts.sort_values(by=\"Anzahl des Tags\",ascending=False)\n",
    "    display(dfCounts)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemeinsames Auftreten von Tags (relativ zum Gesamtvorkommen der Tags)\n",
    "Je näher die Punkte desto öfter werden die Tags zusammen verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Berechnung der relativen Gewichte\n",
    "#Von Datensätzen in denen mindestens einer von beiden Tags vorkommt. Wie oft kommen sie im Verältnis zusammen vor.\n",
    "for key in edges:\n",
    "    for key2 in edges[key]:\n",
    "        edges[key][key2] = edges[key][key2]  /  (totalPerTagCount[key]+totalPerTagCount[key2]-edges[key][key2]) #(stellen an denen beide Tags vorkommen werden nur einmal gezält)\n",
    "        \n",
    "#Erstelleng des Netzwerkdiagramms\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(words[\"sensationTags\"], type=\"sensationTags\")\n",
    "G.add_nodes_from(words[\"emotionTags\"], type=\"emotionTags\")\n",
    "G.add_nodes_from(words[\"metaphors\"], type=\"metaphors\")\n",
    "G.add_nodes_from(words[\"usageExamples\"], type=\"usageExamples\")\n",
    "\n",
    "\n",
    "#Graph auffüllen mit allen Infromationen\n",
    "for key in edges:\n",
    "    for key2 in edges[key]:\n",
    "        if edges[key][key2] > 0:\n",
    "            G.add_edge(key, key2, weight=edges[key][key2])\n",
    "\n",
    "#Ausgabe des Netzwerkdiagramms\n",
    "color_map = []\n",
    "for node in G:\n",
    "    if G.nodes[node]['type'] == \"sensationTags\":\n",
    "        color_map.append('red')\n",
    "    elif G.nodes[node]['type'] == \"emotionTags\":\n",
    "        color_map.append('blue')\n",
    "    elif G.nodes[node]['type'] == \"metaphors\":\n",
    "        color_map.append('green')\n",
    "    elif G.nodes[node]['type'] == \"usageExamples\":\n",
    "        color_map.append('purple')\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.legend(handles=legend_handles)\n",
    "plt.title(\"Kookkurrenz Relativ\")\n",
    "pos = nx.spring_layout(G, weight='weight',k=1,iterations=1000,scale=1) \n",
    "edge_weights = nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, node_color=color_map, edge_color='gray', node_size=300, font_size=4,width = 00.1)\n",
    "\n",
    "nx.write_gexf(G, \"graphRalativ.gexf\")\n",
    "plt.savefig(\"graphRelativ.svg\")\n",
    "plt.savefig(\"graphRekativ.png\")\n",
    "            \n",
    "#Adjazenzmatrix\n",
    "adjRelative =nx.to_pandas_adjacency(G)\n",
    "adjRelative.to_csv(\"relative.csv\",  sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = r\"C:\\Users\\Domin\\OneDrive\\HTW\\Bachelorarbeit\\WAVTactilTransformer\\viblib\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Hauptplot erstellen\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30,30)\n",
    "fig.dpi = 300\n",
    "fig.patch.set_alpha(0)\n",
    "nx.draw(G, pos, with_labels=True, node_color=color_map, edge_color='gray', node_size=300, font_size=4,width = 00.1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# ax.patch.set_alpha(0)\n",
    "# fig2, ax2 = plt.subplots()\n",
    "# fig2.set_size_inches(30,30)\n",
    "# fig2.dpi = 300\n",
    "# fig2.patch.set_alpha(0)\n",
    "# ax2.set_xticks([])\n",
    "# ax2.set_yticks([])\n",
    "# ax2.patch.set_alpha(0)\n",
    "# fig3, ax3 = plt.subplots()\n",
    "# fig3.set_size_inches(30,30)\n",
    "# fig3.dpi = 300\n",
    "# fig3.patch.set_alpha(0)\n",
    "# ax3.set_xticks([])\n",
    "# ax3.set_yticks([])\n",
    "# ax3.patch.set_alpha(0)\n",
    "# fig4, ax4 = plt.subplots()\n",
    "# fig4.set_size_inches(30,30)\n",
    "# fig4.dpi = 300\n",
    "# fig4.patch.set_alpha(0)\n",
    "# ax4.set_xticks([])\n",
    "# ax4.set_yticks([])\n",
    "# ax4.patch.set_alpha(0)\n",
    "\n",
    "\n",
    "#figs = [fig,fig2,fig3,fig4]\n",
    "figs = [fig]\n",
    "\n",
    "# #ax.plot([0, 1, 2, 3, 4], [10, 20, 25, 30, 40], label=\"Hauptdaten\")\n",
    "\n",
    "import os\n",
    "from main import openFile\n",
    "def loadWAF(name):\n",
    "#Lädt json Datei und gibt Inhalt als string zurück\n",
    "  file = os.path.join(wav_path, name + \".wav\")\n",
    "  if os.path.exists(file):\n",
    "    vibration_arr , sr = openFile(file)\n",
    "    return vibration_arr\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "# Schwerpunkt der Vibrationen:\n",
    "import numpy\n",
    "focus_points_vibr = {}\n",
    "for index, row in df.iterrows():\n",
    "    line = (row[\"sensationTags\"]+\",\"+row[\"emotionTags\"]+\",\"+row[\"metaphors\"]+\",\"+row[\"usageExamples\"]).split(\",\")\n",
    "    points=[]\n",
    "    for tag in line:\n",
    "        points.append(pos[tag])\n",
    "    focus_points_vibr[index] = numpy.mean(points, axis = 0)\n",
    "print(focus_points_vibr)\n",
    "colors = [\"red\",\"green\",\"blue\",\"violet\",\"orange\"]\n",
    "i = 0\n",
    "for index in focus_points_vibr:\n",
    "    \n",
    "    # fig.text(focus_points_vibr[index][0],focus_points_vibr[index][1],index,fontsize=3,color=\"orange\")\n",
    "    vib_arr = loadWAF(index)\n",
    "    if vib_arr is None:\n",
    "        i+=1\n",
    "        continue\n",
    "               #[i%4]\n",
    "    mini2 = figs[0].add_axes([(focus_points_vibr[index][0]+1)/2, (focus_points_vibr[index][1]+1)/2, 0.01 * (len(vib_arr)/16000), 0.01])\n",
    "    mini2.plot(vib_arr, label=\"Mini-Daten\", color=colors[i%5],linewidth=0.03)\n",
    "    mini2.set_title(index, fontsize=3)\n",
    "    mini2.patch.set_alpha(0)\n",
    "    mini2.set_xticks([])\n",
    "    mini2.set_yticks([])\n",
    "    i+=1\n",
    "\n",
    "for i, fi in enumerate(figs):\n",
    "   fi.savefig(f\"NetzplotTotal_{i}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenschaften der Tags Farbkarte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "def colored_plot(property1, property2,property3):\n",
    "    color_propety_map = {}\n",
    "    scale1=[numpy.min(numpy.nan_to_num([analysePerTag[tag][property1] for tag in analysePerTag])),numpy.max(numpy.nan_to_num([analysePerTag[tag][property1] for tag in analysePerTag]))]\n",
    "    scale2=[numpy.min(numpy.nan_to_num([analysePerTag[tag][property2] for tag in analysePerTag])),numpy.max(numpy.nan_to_num([analysePerTag[tag][property2] for tag in analysePerTag]))]\n",
    "    scale3=[numpy.min(numpy.nan_to_num([analysePerTag[tag][property3] for tag in analysePerTag])),numpy.max(numpy.nan_to_num([analysePerTag[tag][property3] for tag in analysePerTag]))]\n",
    "    \n",
    "    for tag in pos:\n",
    "        cValueR = (analysePerTag[tag][property1]-scale1[0])/(scale1[1]-scale1[0])\n",
    "        cValueG = (analysePerTag[tag][property2]-scale2[0])/(scale2[1]-scale2[0])\n",
    "        cValueB = (analysePerTag[tag][property3]-scale3[0])/(scale3[1]-scale3[0])\n",
    "        color_propety_map[tag] = [cValueR, cValueG, cValueB]\n",
    "\n",
    "        \n",
    "        #color_propety_map[tag] = [0,0,0]\n",
    "    \n",
    "\n",
    "    points = numpy.array(list(pos.values()))\n",
    "    #points = numpy.array([[-point[1],point[0]] for point in points])\n",
    "    colors = numpy.array(list(color_propety_map.values()))\n",
    "    numpy.nan_to_num(colors,copy=False,nan = 1)\n",
    "\n",
    "    # Bestimme die Extents, damit sie zu den Koordinaten des Graphen passen\n",
    "    min_x, min_y = points.min(axis=0)\n",
    "    max_x, max_y = points.max(axis=0)\n",
    "\n",
    "    grid_x, grid_y = numpy.mgrid[min_y:max_y:100j,min_x:max_x:100j]\n",
    "\n",
    "\n",
    "    grid_colors = griddata(numpy.array([[-point[1],point[0]] for point in points]), colors, (grid_x, grid_y),method='cubic')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    plt.imshow(grid_colors, extent=(min_x,max_x, min_y,max_y))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=colors, edge_color=[0,0,0,0], node_size=300, font_size=4,width = 00.1)  \n",
    "\n",
    "def colored_plot_one(property1):\n",
    "    color_propety_map = {}\n",
    "    scale1=[numpy.min(numpy.nan_to_num([analysePerTag[tag][property1] for tag in analysePerTag])),numpy.max(numpy.nan_to_num([analysePerTag[tag][property1] for tag in analysePerTag]))]\n",
    "\n",
    "    \n",
    "    for tag in pos:\n",
    "        cValueR = (analysePerTag[tag][property1]-scale1[0])/(scale1[1]-scale1[0])\n",
    "\n",
    "        color_propety_map[tag] = [1, 1-cValueR, 1-cValueR]\n",
    "\n",
    "        \n",
    "        #color_propety_map[tag] = [0,0,0]\n",
    "    \n",
    "\n",
    "    points = numpy.array(list(pos.values()))\n",
    "    #points = numpy.array([[-point[1],point[0]] for point in points])\n",
    "    colors = numpy.array(list(color_propety_map.values()))\n",
    "    numpy.nan_to_num(colors,copy=False,nan = 1)\n",
    "\n",
    "    # Bestimme die Extents, damit sie zu den Koordinaten des Graphen passen\n",
    "    min_x, min_y = points.min(axis=0)\n",
    "    max_x, max_y = points.max(axis=0)\n",
    "\n",
    "    grid_x, grid_y = numpy.mgrid[min_y:max_y:100j,min_x:max_x:100j]\n",
    "\n",
    "\n",
    "    grid_colors = griddata(numpy.array([[-point[1],point[0]] for point in points]), colors, (grid_x, grid_y),method='cubic')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    plt.imshow(grid_colors, extent=(min_x,max_x, min_y,max_y))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=colors, edge_color=[0,0,0,0], node_size=300, font_size=4,width = 00.1)   \n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "\"\"\" plt.title(\"Rot: Anzahl der Pausen, Grün: durchschnittliche Dauer einer Pause, Blau: Durchschnittliche Zeit zwischen Pausen\")\n",
    "colored_plot(\"meanBreakCount\", \"meanBreakDuration\",\"meanTimeBetweenBreaks\") \"\"\"\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanDuration\")\n",
    "colored_plot_one(\"meanDuration\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanSignalEnergyWithoutBreaks\")\n",
    "colored_plot_one(\"meanSignalEnergyWithoutBreaks\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanTotalBreakDuration\")\n",
    "colored_plot_one(\"meanTotalBreakDuration\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanTimeBetweenBreaks\")\n",
    "colored_plot_one(\"meanTimeBetweenBreaks\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanBreakCount\")\n",
    "colored_plot_one(\"meanBreakCount\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanBreakDuration\")\n",
    "colored_plot_one(\"meanBreakDuration\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanNoFrequencyChangeDuration\")\n",
    "colored_plot_one(\"meanNoFrequencyChangeDuration\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"MeanNoFrequencyChangeDurationRelative\")\n",
    "colored_plot_one(\"MeanNoFrequencyChangeDurationRelative\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanIncreaseRateFrequency\")\n",
    "colored_plot_one(\"meanIncreaseRateFrequency\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanDecreaseRateFrequency\")\n",
    "colored_plot_one(\"meanDecreaseRateFrequency\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanFrequency\")\n",
    "colored_plot_one(\"meanFrequency\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanNoAmplitudeChangeDuration\")\n",
    "colored_plot_one(\"meanNoAmplitudeChangeDuration\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"MeanNoAmplitudeChangeDurationRelative\")\n",
    "colored_plot_one(\"MeanNoAmplitudeChangeDurationRelative\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanIncreaseRateAmplitude\")\n",
    "colored_plot_one(\"meanIncreaseRateAmplitude\")\n",
    "\n",
    "plt.figure(figsize=(15,15), dpi=300)\n",
    "plt.title(\"meanDecreaseRateAmplitude\")\n",
    "colored_plot_one(\"meanDecreaseRateAmplitude\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjazenzmatrix Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Funktion zum Berechnen der Farbe\n",
    "def color_scale(val):\n",
    "    # Normierung des Werts zwischen 0 und 1\n",
    "    normalized_val = val / 40  # Wert liegt zwischen 0 und 1\n",
    "    \n",
    "    # Berechnung des Grünanteils basierend auf dem normalisierten Wert\n",
    "    green_intensity = int(normalized_val * 255)  # Grünanteil berechnen (zwischen 0 und 255)\n",
    "    \n",
    "    # Erstellen der Farbe im RGB-Format: rgb(255, 255, 255) -> rgb(255, 255, 255 - green_intensity)\n",
    "    return f'background-color: rgb(255, 255, {255-green_intensity})'\n",
    "\n",
    "# Stil anwenden\n",
    "styled_df = adjTotal.style.map(color_scale)\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjazenzmatrix relativ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Berechnen der Farbe\n",
    "def color_scale(val):\n",
    "\n",
    "    \n",
    "    # Berechnung des Grünanteils basierend auf dem normalisierten Wert\n",
    "    yellow_intensity = int(val * 255)  # Grünanteil berechnen (zwischen 0 und 255)\n",
    "    \n",
    "    # Erstellen der Farbe im RGB-Format: rgb(255, 255, 255) -> rgb(255, 255, 255 - green_intensity)\n",
    "    return f'background-color: rgb({255-yellow_intensity}, 255, {255-yellow_intensity})'\n",
    "\n",
    "styled_df = adjRelative.style.map(color_scale)\n",
    "display(styled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WtT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
