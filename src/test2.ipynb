{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File C:\\Users\\Domin\\OneDrive\\HTW\\Bachelorarbeit\\WAVTactilTransformer\\viblib\\testShortSignalDetection\\v-09-11-4-8.json does not exists. Dataset is ignored. Idex: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 119/119 [00:00<00:00, 1183.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['0', '1', 'id', 'text'],\n",
       "        num_rows: 115\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['0', '1', 'id', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# with open('prompts.json') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "csv_path = r\"/content/drive/MyDrive/vibviz/vibrationAnnotations-July24th2016.csv\"\n",
    "json_path = r\"C:\\Users\\Domin\\OneDrive\\HTW\\Bachelorarbeit\\WAVTactilTransformer\\viblib\\testShortSignalDetection\"\n",
    "\n",
    "# EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "EOS_TOKEN = \"EOS_TOKEN\\n\"\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "import os\n",
    "#Lädt json Datei und gibt Inhalt als string zurück\n",
    "def readJson(file_name):\n",
    "  file_path = os.path.join(json_path, file_name + \".json\")\n",
    "  if not os.path.isfile(file_path):\n",
    "    raise Exception(\"File\", file_path, \"does not exists.\")\n",
    "  file = open(file_path,'r')\n",
    "  content = file.read()\n",
    "  file.close()\n",
    "  return content\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "# Datensätze mit fehlender JSON löschen\n",
    "def delete_if_json_is_missing(dataset):\n",
    "  keep_indices = []\n",
    "  for i in range(len(dataset[\"id\"])):\n",
    "    file_path = os.path.join(json_path, dataset[\"id\"][i] + \".json\")\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "      print(\"Warning: File\", file_path, \"does not exists. Dataset is ignored. Idex:\", i)\n",
    "    else:\n",
    "      keep_indices.append(i)\n",
    "  return dataset.select(keep_indices)\n",
    "\n",
    "def value_to_description(value):\n",
    " pass\n",
    "\n",
    "#Formatiert die Daten für das fine tuning-> Rohdaten aus VibViz Datenbank\n",
    "def vibviz_formatting_prompts_func(examples):\n",
    "  instruction = \"Generate an vibrotaktil pattern with following characteristics:\" #Instruction verknüpt im Modell die Aufgabe mit der Eingabe\n",
    "  texts = []\n",
    "  for i in range(len(examples[\"id\"])):\n",
    "    input = \"\"\n",
    "    if examples[\"sensationTags\"][i] is not None:\n",
    "      input = input + examples[\"sensationTags\"][i] + \",\"\n",
    "    if examples[\"emotionTags\"][i] is not None:\n",
    "      input = input + examples[\"emotionTags\"][i] + \",\"\n",
    "    if examples[\"metaphors\"][i] is not None:\n",
    "      input = input + examples[\"metaphors\"][i] + \",\"\n",
    "    if examples[\"usageExamples\"][i] is not None:\n",
    "      input = input + examples[\"usageExamples\"][i]\n",
    "    output = readJson(examples[\"id\"][i])\n",
    "    if output is not None:\n",
    "      text = alpaca_prompt.format(instruction,input,output) + EOS_TOKEN\n",
    "      texts.append(text)\n",
    "  return {\"text\" : texts}\n",
    "\n",
    "def vibviz_formatting_natural_prompts_func(examples):\n",
    "  input = \"\"\n",
    "  texts = []\n",
    "  for i in range(len(examples[\"id\"])):\n",
    "    instruction = examples[\"1\"][i]\n",
    "    output = readJson(examples[\"id\"][i])\n",
    "    text = alpaca_prompt.format(instruction,input,output) + EOS_TOKEN\n",
    "    texts.append(text)\n",
    "  return {\"text\" : texts}\n",
    "\n",
    "  \n",
    "fromCSV = False\n",
    "fromJSON = not fromCSV\n",
    "\n",
    "if fromCSV:\n",
    "\n",
    "    #Datem mit fehlender json aussortieren\n",
    "    #dataset = delete_if_json_is_missing(dataset)\n",
    "\n",
    "    #dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
    "    #Daten formatieren \"mapen\" für das Training\n",
    "    dataset = dataset.map(vibviz_formatting_prompts_func, batched = True,)\n",
    "\n",
    "if fromJSON:\n",
    "    #Daten laden\n",
    "  import json\n",
    "  import pandas as pd\n",
    "  import datasets\n",
    "  with open('prompts.json') as f:\n",
    "      data = json.load(f)\n",
    "  \n",
    "  df = pd.DataFrame.from_dict(data, orient='index')\n",
    "  \n",
    "  datasets.Dataset.from_pandas(df)\n",
    "\n",
    "  dataset = datasets.Dataset.from_pandas(df, split=\"train\").rename_column(\"__index_level_0__\",\"id\")\n",
    "\n",
    "  \n",
    "  dataset = delete_if_json_is_missing(dataset)\n",
    "  #Daten formatieren \"mapen\" für das Training\n",
    "  dataset = dataset.map(vibviz_formatting_natural_prompts_func, batched = True,)\n",
    "\n",
    "# Entimmt aus den Trainingsdaten zufällige Testdatem\n",
    "if True:\n",
    "  dataset = dataset.train_test_split(test_size = 0.03, shuffle = True, seed = 3407)\n",
    "dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WtT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
